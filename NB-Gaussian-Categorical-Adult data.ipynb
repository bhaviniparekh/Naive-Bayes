{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Adult data set used in code to see how we can handle both categorical and continuous data. Both types of data are handled\n",
    "differently. After reading the data in the data frame, data is split in X(input) and Y(output/label)data. The X data and Y data\n",
    "are then train-test split to get training and testing data. Till now training and testing both have categorical and continuous \n",
    "data. We now need to separate categorical and continuous data from training data and store them in a different data frame.\n",
    "\n",
    "\n",
    "For categorical data, we calculate the conditional probability. Training data is iterated over columns. For every unique value of column conditional probability is calculated with every unique value of the Y data label\n",
    "eg For column Color there are 2 unique value Red, Yellow.Y data as 2 unique value Yes and No.We calculate the conditional\n",
    "probability of Red|No,Red|Yes,Yellow|No,Yellow|Yes etc. \n",
    "This data is stored in an dictionary object against every column ({'Color': {'YellowYes': 0.5,\n",
    "  'YellowNo': 0.57,'RedYes': 0.5,........etc)\n",
    "\n",
    "For continuous data, training data is fit on GaussianNB object. Std and mean are calculated for every column. The column values\n",
    "are then scaled to Z -score using the Z-score formula. Training data columns are transformed into Z-score after this process. A model is ready to predict \n",
    "continuous data. On the same object, test data is predicted. For every unique value of Y data, test data is predicted. The prediction\n",
    "of test data for every class is populated in a data frame.\n",
    "\n",
    "\n",
    "For Y data, probabilty is calculated for every unique value and stored in dictionary.eg Yes:80,No:76 etc..\n",
    "\n",
    "The model is now ready to predict the test data. The test data is iterated over row. For every row, the corresponding columns\n",
    "are matched with continuous and categorical training data frames. If the columns of the given row belong to continuous type\n",
    "then respective column|class probability is obtained from the dictionary object(Check paragraph 3). For the categorical column,\n",
    "the probability is obtained from the dictionary object(Check paragraph 2). The probability of each column |class is multiplied to\n",
    "get a cumulative probability for a given row. The same process is repeated for all unique class. The class|probabilty is stored\n",
    "in the dictionary object. The class having maximum probability is will be the prediction of the given row. A list is populated with\n",
    "prediction got this way for every row of testing data.\n",
    "\n",
    "The prediction got for every row from above along with actual class is used to calculate the accuracy score.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from IPython.display import display\n",
    "import math\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    This function is to read data using Pandas read_csv function and convert into dataframe.\n",
    "    \n",
    "      \n",
    "    Return :- Dataframe\n",
    "    '''\n",
    "    \n",
    "    data=pd.read_csv('http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.data',names=['Age','Workclass','FNLWGT','Education','Education-Num','Marital Status','Occupation','Relationship','Race','Sex','Capital Gain','Caplital Loss','Hrs-Per-Week','Native-Country','Sal'])\n",
    "    \n",
    "    for col in data.columns:\n",
    "\n",
    "        data[col].replace(' ?',data[col].mode()[0],inplace=True)\n",
    "        \n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \n",
    "    '''\n",
    "    The function is to split data first into the Input (X) and Output (Y) dataset. The X data is further train-test split into\n",
    "     x_train,y_train,x_test,y_test data.\n",
    "    \n",
    "    Argument :-\n",
    "    dfnew :-Modified adult dataframe\n",
    "    \n",
    "    Return :- \n",
    "    xtrain:-training data\n",
    "    xtest :- Validation data\n",
    "    ytrain :- Label data of training data\n",
    "    ytest :- label data of validation data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    x=df.iloc[:,:-1]\n",
    "    y=df.iloc[:,-1]\n",
    "    \n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.3,random_state=0)\n",
    "    \n",
    "    return xtrain,xtest,ytrain,ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cat_cont_split(x_train,y_train,x_test,y_test):\n",
    "    '''\n",
    "    The function is to separate continuous and categorical columns of training and test data into different data frames.\n",
    "    The class of respective training and test data are concatenated with the above data frame for further use.\n",
    "    \n",
    "    \n",
    "    Argument :- \n",
    "    x_train  :- Training data\n",
    "    y_train   :- class of training data\n",
    "    x_test    :- Testing data\n",
    "    y_test    :- class of testing data\n",
    "    \n",
    "    Return :- \n",
    "    x_cont_df  :- Continuous columns of training data concatenated with x_test\n",
    "    x_cat_df   :- Categorical columns of training data concatenated with x_test\n",
    "    x_cont_data :-Continuous columns of training data\n",
    "    x_cat_data :- Categorical columns of training data\n",
    "    x_test_cont_data :-Continuous columns of test data\n",
    "    x_test_cat_data :-Categorical columns of test data\n",
    "    x_test_cat_df  :-Categorical columns of test data concatenated with y_test\n",
    "    \n",
    "      \n",
    "    '''\n",
    "    \n",
    "    #split x_train data into continuous data and concatenate with y_train to find the probability.Converting series to a data frame.\n",
    "    x_cont_data=x_train[['Age','FNLWGT','Education-Num','Capital Gain','Caplital Loss','Hrs-Per-Week']]\n",
    "    x_cont_df=pd.concat([x_cont_data,y_train],axis=1)\n",
    "   \n",
    "    \n",
    "    \n",
    "    #split x_train data into categorical data and concatenate with y_train.\n",
    "    x_cat_data=x_train[['Workclass','Education','Marital Status','Occupation','Relationship','Race','Sex','Native-Country']]\n",
    "    x_cat_df=pd.concat([x_cat_data,y_train],axis=1)\n",
    "    \n",
    "    #split x_test data into continuous data\n",
    "    x_test_cont_data=x_test[['Age','FNLWGT','Education-Num','Capital Gain','Caplital Loss','Hrs-Per-Week']]\n",
    "    \n",
    "    \n",
    "    #split x_test data into categorical data\n",
    "\n",
    "    x_test_cat_data=x_test[['Workclass','Education','Marital Status','Occupation','Relationship','Race','Sex','Native-Country']]\n",
    "    x_test_cat_df=pd.concat([x_test_cat_data,y_test],axis=1)\n",
    "    \n",
    "    \n",
    "    return x_cont_df,x_cat_df,x_cont_data,x_cat_data,x_test_cont_data,x_test_cat_data,x_test_cat_df\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prob(y_train):\n",
    "    \n",
    "    '''\n",
    "    This function is to calculate the probability of unique values of the Output data.\n",
    "    \n",
    "    Argument :- \n",
    "    y_train :- Ytrain data to get probabilty of output columns\n",
    "    \n",
    "    Return :-  \n",
    "    outdict :-Dictionary holding probabilty of each unique value of output data.\n",
    "    unq_out :- Unique value of Y data.\n",
    "    '''\n",
    "    \n",
    "    #Find unique value of Output column and rowcount of y_train data \n",
    "    unq_out=y_train.unique()\n",
    "    rowcnt=y_train.shape[0]\n",
    "    outdict={}\n",
    "    \n",
    "    \n",
    "    # Getting probablity of ouput column for unqiue values\n",
    "    for k in unq_out:\n",
    "        prob=y_train[y_train==k].shape[0]/rowcnt\n",
    "        outdict.update({k:prob})\n",
    "\n",
    "    return outdict,unq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_std_mean(xtrain_cont_data,y_train,xtest_cont_data):\n",
    "    '''\n",
    "    For continuous data, training data is fit on GaussianNB object. Std and mean are calculated for every column. The column values\n",
    "    are then scaled to Z -score using the Z-score formula. Training data columns are transformed into Z-score after this process\n",
    "    A model is ready to predict continuous data. On the same object, test data is predicted. For every unique value of Y data,\n",
    "    test data is predicted. The prediction of test data for every class is populated in a data frame.\n",
    "    \n",
    "    Argument :- \n",
    "    xtrain_cont_data :-Continuous data of training data set\n",
    "    y_train          :- class of training data\n",
    "    xtest_cont_data  :-Continuous data of test data\n",
    "    \n",
    "    \n",
    "    Return :-\n",
    "    xtrain_cont_data :- Transformed continuos data of training data set\n",
    "    x_test_cont_df :- Data frame with only class prediction for continuous data of test data set.\n",
    "    \n",
    "    '''\n",
    "    # Creating object of gaussianNB calss\n",
    "    clf = GaussianNB()\n",
    "    \n",
    "    #This is to calculate sigma and Mu of every column of x_train\n",
    "    clf=clf.fit(xtrain_cont_data,y_train)\n",
    "    \n",
    "    # On the same object ,fit the test data on training.Create a df with zcore values.\n",
    "    x_test_cont_df=pd.DataFrame(clf.predict_proba(xtest_cont_data), columns=clf.classes_)\n",
    "    \n",
    "    return xtrain_cont_data,x_test_cont_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cat_prob(xtrain_cat_data,y_train,xtrain_cat_df):\n",
    "    '''\n",
    "    Calculate probability of training catogorical data eg Red nYes,Red nNo etc\n",
    "    Populate dictionary with column and probabilty of unique values of column n class label unique values.\n",
    "    Laplace smoothing in taken in to consideration for zero values in columns.\n",
    "    \n",
    "    \n",
    "    Argument :- training catogorical data,ytrain data\n",
    "    \n",
    "    Return :- dictionary holding column:{RedNyes:prob} \n",
    "    \n",
    "    '''\n",
    " \n",
    "    #Finding probablity of categorical data with output column\n",
    "    xcat_prob={}\n",
    "    unq_ytrain=y_train.unique()\n",
    "    for col in xtrain_cat_data.columns:\n",
    "            colunq=xtrain_cat_data[col].unique()\n",
    "    \n",
    "            newdict={}\n",
    "    \n",
    "            for val in colunq:\n",
    "     \n",
    "                for val1 in unq_ytrain:\n",
    "            \n",
    "                    result = (xtrain_cat_df[(xtrain_cat_df[col]==val) & (xtrain_cat_df[y_train.name]==val1)].shape[0]+1)\n",
    "                    prob=result/(xtrain_cat_df[xtrain_cat_df[y_train.name]==val1].shape[0]+len(unq_ytrain))\n",
    "            \n",
    "                    newdict.update({val+val1:prob})\n",
    "        \n",
    "            xcat_prob.update({col:newdict})\n",
    "    return xcat_prob\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(xtestcat_cont,xtest_cont_df,xtest_cat_data,xtrain_cat_prob,y_train):\n",
    "    \n",
    "    '''\n",
    "    Predict test data both catogorical and continious data against.\n",
    "    Iterate every row of test data.For every row check the column if catogorical use training catgorical probablity,\n",
    "    if column of the row is continous data,use test continous probabilty df.\n",
    "    Need to multiple every column probabilty for a given row.\n",
    "    Each row will have 2 probabilty or more based on nos of unique values in class.Update the class lable:prob in a dictinary.\n",
    "    Before the start of new row ,get the max probabilty and store the corresponding class lable in a dict\n",
    "    The class value predict for a given row ,at the end of test data is used to calculate Accuracy score.\n",
    "    \n",
    "    \n",
    "    Argument :- test cat and cont prob data,test probabilty df,test catogorical data,training conditional probabilty of\n",
    "                catogorical data,ytrain data\n",
    "    \n",
    "    Return :- Array of predicted value.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    p=0\n",
    "    d={}\n",
    "    xtest_prob={}\n",
    "    unq_ytrain=y_train.unique()\n",
    "    Ypred=[]\n",
    "    val=''\n",
    "    \n",
    "    for index,row in xtestcat_cont.iterrows():\n",
    "    \n",
    "       \n",
    "        # Iterating to every unique values of output column\n",
    "        for val in unq_ytrain:\n",
    "        \n",
    "            prob=1\n",
    "        \n",
    "                \n",
    "            #Iterating through every col in xtestcat_cont row:\n",
    "            for ind in row.index:\n",
    "                \n",
    "                   \n",
    "                if ind in(xtest_cont_df.columns):\n",
    "                    prob=xtest_cont_df[val].loc[index]\n",
    "                    \n",
    "            \n",
    "                    prob=prob*p\n",
    "                \n",
    "            # Check whether that row exist in training contionus data or in training catogorical data.According handle.\n",
    "            \n",
    "                if ind in(xtest_cat_data.columns):\n",
    "                    \n",
    "                \n",
    "                    d=xtrain_cat_prob[ind]\n",
    "                    \n",
    "               \n",
    "                    p=d[row.get(ind)+val]\n",
    "                    prob=prob*p\n",
    "                    \n",
    "                xtest_prob.update({val:prob})\n",
    "                ##Get the class with highest probability.This will be prediction of the given row.\n",
    "        max_v = max(zip(xtest_prob.values(), xtest_prob.keys()))\n",
    "        Ypred.append(max_v[1])\n",
    "    return Ypred\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyfunc(ypredect,ytest):\n",
    "    \n",
    "    '''\n",
    "    The function is to calculate the accuracy score with predicted data and actual labels.\n",
    "    \n",
    "    Argument :- \n",
    "    ypredect  :-List of prediction for every row of validation data.\n",
    "    y_test    :- Actual class for every row of validation data.\n",
    "    \n",
    "    Return :- \n",
    "    accuracy  :- Accuracy score of the algorithm\n",
    "    '''\n",
    "    \n",
    "    ytest=ytest.tolist()\n",
    "\n",
    "    ytestrow=len(ytest)\n",
    "\n",
    "    cntrow=0\n",
    "    accuracy=0\n",
    "    \n",
    "    for x,y in zip(ytest,ypredect):\n",
    "        \n",
    "        if x==y:\n",
    "            cntrow=cntrow+1\n",
    "  \n",
    "    accuracy=cntrow*100/ytestrow\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data in pandas data frame\n",
    "df=read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split the data into training and testing data.\n",
    "x_train,x_test,y_train,y_test=preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store continuous and categorical columns of training and testing data into different data frames.\n",
    "xtrain_cont_df,xtrain_cat_df,xtrain_cont_data,xtrain_cat_data,xtest_cont_data,xtest_cat_data,xtest_cat_df=train_cat_cont_split(x_train,y_train,x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Built a training model.Find the std and mean for every column|class.Find the probability of continuous data of testing data.\n",
    "xtrain_cont_data,xtest_cont_df=Gaussian_std_mean(xtrain_cont_data,y_train,xtest_cont_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the prediction of continuous data of testing with categorical data of testing.\n",
    "xtest_cat_data=xtest_cat_data.reset_index(drop=True)\n",
    "xtest_cont_df.index=xtest_cat_data.index\n",
    "xtestcat_cont=pd.concat([xtest_cat_data,xtest_cont_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate probability of every unique value of Y data.\n",
    "class_dict,unqout=class_prob(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcualate probability of categorical columns of training data.\n",
    "xtrain_cat_prob=train_cat_prob(xtrain_cat_data,y_train,xtrain_cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the test data\n",
    "ypred=predict_test(xtestcat_cont,xtest_cont_df,xtest_cat_data,xtrain_cat_prob,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the accuracy score.\n",
    "accuracy_val=accuracyfunc(ypred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.752277612857"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
