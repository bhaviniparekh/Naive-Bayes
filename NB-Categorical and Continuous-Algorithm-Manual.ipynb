{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Car data set used in the code to see how we can handle both categorical and continuous data. Both types of data are handled\n",
    "differently. After reading the data in the data frame, data is split in X(input) and Y(output/label)data. The X data and Y data\n",
    "are then train-tet split to get training and testing data. Till now training and testing both have categorical and continuous \n",
    "data. We now need to separate categorical and continuous data from training data and store them in a different data frame.\n",
    "\n",
    "\n",
    "For categorical data, we calculate the conditional probability. Training data is iterated over columns. For every unique value\n",
    "of column conditional probability is calculated with every unique value of the Y data label\n",
    "eg For column Color there are 2 unique value Red, Yellow.Y data as 2 unique value Yes and No.We calculate the conditional\n",
    "probability of Red|No,Red|Yes,Yellow|No,Yellow|Yes etc. \n",
    "This data is stored in an dictionary object against every column ({'Color': {'YellowYes': 0.5,\n",
    "  'YellowNo': 0.57,'RedYes': 0.5,........etc)\n",
    "\n",
    "For continuous data, training data is iterated over the column. The conditional probability is calculated for every \n",
    "column|unique class.\n",
    "Both std and mean are calculated this way for every column|unique class and stored in a dictionary object.\n",
    "eg {'Age': {'StdYes': 0.0,'MeanYes': 10.0,......etc\n",
    "\n",
    "For Y data, probabilty is calculated for every unique value and stored in dictionary.eg Yes:80,No:76 etc..\n",
    "\n",
    "The model is now ready to predict the test data. The test data is iterated over row. For every row, the corresponding columns\n",
    "are matched with continuous and categorical training data frames. If the columns of the given row belong to continuous type\n",
    "then respective column|class probability is obtained from the dictionary object(Check paragraph 3). For the categorical column,\n",
    "the probability is obtained from the dictionary object(Check paragraph 2). The probability of each column |class is multiplied to\n",
    "get a cumulative probability for a given row. The same process is repeated for all unique class. The class|probabilty is stored\n",
    "in the dictionary object. The class having maximum probability is will be the prediction of the given row. A list is populated with\n",
    "prediction got this way for every row of testing data.\n",
    "\n",
    "The prediction got for every row from above along with actual class is used to calculate the accuracy score.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from IPython.display import display\n",
    "import math\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    '''\n",
    "    This function is to read data using Pandas read_csv function and convert into dataframe.\n",
    "    \n",
    "      \n",
    "    Return :- Dataframe\n",
    "    '''\n",
    "    \n",
    "    data=pd.read_csv('D:\\Dataset\\Car-dataset-mixed.csv')\n",
    "    \n",
    "    for col in data.columns:\n",
    "\n",
    "        data[col].replace(' ?',data[col].mode()[0],inplace=True)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \n",
    "    '''\n",
    "    The function is to split data first into the Input (X) and Output (Y) dataset. The X data is further train-test split into\n",
    "     x_train,y_train,x_test,y_test data.\n",
    "    \n",
    "    Argument :-\n",
    "    df :-Modified adult dataframe\n",
    "    \n",
    "    Return :- \n",
    "    xtrain:-training data\n",
    "    xtest :- Validation data\n",
    "    ytrain :- Label data of training data\n",
    "    ytest :- label data of validation data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    x=df.iloc[:,:-1]\n",
    "    y=df.iloc[:,-1]\n",
    "    \n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.3,random_state=0)\n",
    "    \n",
    "    return xtrain,xtest,ytrain,ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cat_cont_split(x_train,y_train):\n",
    "    '''\n",
    "    Split the train data into catogorical and continous data.\n",
    "    Concatenate ytrain data to above created new data frame.\n",
    "    \n",
    "    \n",
    "    Argument :- \n",
    "    x_train :- Training data.\n",
    "    y_train :- Y data of training data set.\n",
    "    \n",
    "    Return :- \n",
    "    x_cont_df :- xtrain continous data\n",
    "    x_cat_df :- Data frame containing categorical data of training data set and respective Y data.\n",
    "    x_cont_data :- Data frame containing continuous columns of training data set\n",
    "    x_cat_dat :- Data frame containing categorical columns of training data set.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #split x_train data into continuous data and concatenate with y_train.Converting series to a data frame.\n",
    "    x_cont_data=x_train.iloc[:,0]\n",
    "    x_cont_df=pd.concat([x_cont_data,y_train],axis=1)\n",
    "    x_cont_data=x_cont_data.to_frame()\n",
    "    \n",
    "    \n",
    "    #split x_train data into categorical data and concatenate with y_train.\n",
    "\n",
    "    x_cat_data=x_train.iloc[:,1:4]\n",
    "    x_cat_df=pd.concat([x_cat_data,y_train],axis=1)\n",
    "    \n",
    "    return x_cont_df,x_cat_df,x_cont_data,x_cat_data\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prob(y_train):\n",
    "    \n",
    "    '''\n",
    "    This function is to calculate the probability of unique values of the Output data.\n",
    "    \n",
    "    Argument :- \n",
    "    y_train :- Y train data.\n",
    "    \n",
    "    Return :-  \n",
    "    outdict :-Dictionary holding probabilty of each unique value of output data.\n",
    "    unq_out :- Unique value of Y data.\n",
    "    '''\n",
    "    \n",
    "    #Find unique value of Output column and rowcount of y_train data \n",
    "    unq_out=y_train.unique()\n",
    "    rowcnt=y_train.shape[0]\n",
    "    outdict={}\n",
    "    \n",
    "    \n",
    "    # Getting probablity of ouput column for unqiue values\n",
    "    for k in unq_out:\n",
    "        prob=y_train[y_train==k].shape[0]/rowcnt\n",
    "        outdict.update({k:prob})\n",
    "\n",
    "    return outdict,unq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_mean_cal(xtrain_cont_data,xtrain_cont_df,y_train):\n",
    "    \n",
    "    '''\n",
    "For continous data,training data is iterated over column.The conditional probability is calculated for every column|unique class\n",
    "Both std and mean are calculated this way and stored in an dictionary object.\n",
    "eg {'Age': {'StdYes': 0.0,'MeanYes': 10.0,......etc\n",
    "   \n",
    "    \n",
    "    Argument :- \n",
    "    xtrain_cont_data :- Data frame with continuous columns of training data set\n",
    "    xtran_cont_df    :- Data frame with continuous columns and respective Y data.\n",
    "    y_train :- Y data\n",
    "    \n",
    "    Return :- \n",
    "    train_cont_std_mean   :- Dictionary containing std and mean.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #Calculate manually std and mean for every continuous column data of training data set and store in a dictionary against \n",
    "    #each column name.\n",
    "\n",
    "    unq_ytrain=y_train.unique()\n",
    "    train_cont_std_mean={}\n",
    "\n",
    "    for col in xtrain_cont_data.columns:\n",
    "        newdict={}\n",
    "    \n",
    "        for unq in unq_ytrain:\n",
    "        \n",
    "            col_std=xtrain_cont_df[xtrain_cont_df[y_train.name]==unq][col].std()\n",
    "            newdict.update({'Std'+unq:col_std})\n",
    "            col_mean=xtrain_cont_df[xtrain_cont_df[y_train.name]==unq][col].mean()\n",
    "            newdict.update({'Mean'+unq:col_mean})\n",
    "    \n",
    "    \n",
    "        train_cont_std_mean.update({col:newdict})\n",
    "    return train_cont_std_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cat_prob(xtrain_cat_data,y_train,xtrain_cat_df):\n",
    "    '''\n",
    "    This function is to calculate the probability of categorical data of training eg Red nYes,Red nNo etc.\n",
    "    The conditional probability is calculated from every unique value of column | unique class (Red|yes.Red|No..etc).The Laplace\n",
    "    smoothing is implemented to avoid 0 probability.\n",
    "    This data is stored in an dictionary object against every column ({'Color': {'YellowYes': 0.5,'YellowNo': 0.57,'RedYes': 0.5,..\n",
    "    ....etc)\n",
    "      \n",
    "    \n",
    "    Argument :-\n",
    "    xtrain_cat_data :- Data frame containing categorical columns of training data set\n",
    "    y_train         :- Y train data.\n",
    "    xtrain_cat_df   :- Data frame containing categorical columns of training data set and respective Y data.\n",
    "    \n",
    "    Return :- \n",
    "    xcat_prob  :- dictionary holding probabilty:{RedNyes:prob} \n",
    "    \n",
    "    '''\n",
    " \n",
    "    #Finding probablity of categorical data with output column\n",
    "    xcat_prob={}\n",
    "    unq_ytrain=y_train.unique()\n",
    "    for col in xtrain_cat_data.columns:\n",
    "            colunq=xtrain_cat_data[col].unique()\n",
    "    \n",
    "            newdict={}\n",
    "    \n",
    "            for val in colunq:\n",
    "     \n",
    "                for val1 in unq_ytrain:\n",
    "            \n",
    "                    result = (xtrain_cat_df[(xtrain_cat_df[col]==val) & (xtrain_cat_df[y_train.name]==val1)].shape[0]+1)\n",
    "                    prob=result/(xtrain_cat_df[xtrain_cat_df[y_train.name]==val1].shape[0]+len(unq_ytrain))\n",
    "            \n",
    "                    newdict.update({val+val1:prob})\n",
    "        \n",
    "            xcat_prob.update({col:newdict})\n",
    "    return xcat_prob\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(x_test,y_train,train_std_mean,xtrain_cat_prob,xtrain_cont_data,xtrain_cat_data):\n",
    "    \n",
    "    '''\n",
    "    The test data is iterated over row. For every row, the corresponding columns are matched with continuous and categorical \n",
    "    training data frames.If the columns of the given row belong to continuous type then respective column|class probability is\n",
    "    obtained from the dictionary object. For the categorical column,probability is obtained from the dictionary object obtained\n",
    "    above.The probability of each column |class is multiplied to get a cumulative probability for a given row.\n",
    "    The same process is repeated for all unique class. The class|probabilty is stored in the dictionary object.The class having\n",
    "    maximum probability is predicted for that row. \n",
    "    \n",
    "    \n",
    "    Argument:- \n",
    "    x_test           :- Validation data\n",
    "    y_train           :- Output columnn data\n",
    "    train_std_mean    :- dictionary holding std and mean for unique value of the training data columns.\n",
    "    xtrain_cat_prob   :- Dictionary holding probabilty of categorical column.\n",
    "    xtrain_cont_data  :- Data frame of columns with continuous data and respective Y data\n",
    "    xtrain_cat_data   :- Data frame of columns with categorical data and respective Y data.\n",
    "    \n",
    "    \n",
    "    Return :- \n",
    "    Ypred            :- List of prediction for every row of validation data.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    p=0\n",
    "    d={}\n",
    "    xtest_prob={}\n",
    "    unq_ytrain=y_train.unique()\n",
    "    Ypred=[]\n",
    "    val=''\n",
    "    \n",
    "    #Iterating every row in x_test data\n",
    "    for index,row in x_test.iterrows():\n",
    "    \n",
    "        for val in unq_ytrain:\n",
    "            prob=1\n",
    "        \n",
    "                \n",
    "            #for every col in x_test rows:\n",
    "            for ind in row.index:\n",
    "                \n",
    "                 \n",
    "                 # Check whether that row exist in training contionus data or in training catogorical data.   \n",
    "                if ind in(xtrain_cont_data.columns):\n",
    "                \n",
    "                \n",
    "                    pstd=0\n",
    "                    pmean=0\n",
    "                    denom=0\n",
    "                    num=0\n",
    "                    d=train_std_mean[ind]\n",
    "                \n",
    "                    pstd=d['Std'+val]\n",
    "                \n",
    "                    pstd=pstd**2\n",
    "                \n",
    "                    pmean=d['Mean'+val]\n",
    "                    \n",
    "                    if pstd ==0 :\n",
    "                        pstd=1\n",
    "                \n",
    "                \n",
    "                    denom=math.sqrt(2*math.pi*pstd)\n",
    "                \n",
    "                    num=math.exp(-(row.get(ind)-pmean)**2/(2*pstd))\n",
    "                   \n",
    "                    p=num/denom\n",
    "                    prob=prob*p\n",
    "            \n",
    "                if ind in(xtrain_cat_data.columns):\n",
    "                    \n",
    "                \n",
    "                    d=xtrain_cat_prob[ind]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if row.get(ind)+val in d.keys() :\n",
    "                        p=d[row.get(ind)+val]\n",
    "                        \n",
    "                    \n",
    "                        prob=prob*p\n",
    "                    \n",
    "                #Multipling all columns probabilty(both continious and catogorical data P(A1)*P(A2)*P(A3)……P(An)),\n",
    "                #to get final row wise probabilty.\n",
    "               \n",
    "            xtest_prob.update({val:prob})\n",
    "           \n",
    "       \n",
    "        #Get the class with highest probability.This will be prediction of the given row.\n",
    "        \n",
    "        \n",
    "        max_v = max(zip(xtest_prob.values(), xtest_prob.keys()))\n",
    "        \n",
    "        Ypred.append(max_v[1])\n",
    "    \n",
    "    return Ypred\n",
    "                \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyfunc(ypredect,ytest):\n",
    "    \n",
    "    '''\n",
    "    The function is to calculate the accuracy score with predicted data and actual labels.\n",
    "    \n",
    "    Argument :- \n",
    "    ypredect  :-List of prediction for every row of validation data.\n",
    "    y_test    :- Actual class for every row of validation data.\n",
    "    \n",
    "    Return :- \n",
    "    accuracy  :- Accuracy score of the algorithm\n",
    "    '''\n",
    "    \n",
    "    ytest=ytest.tolist()\n",
    "\n",
    "    ytestrow=len(ytest)\n",
    "\n",
    "    cntrow=0\n",
    "    accuracy=0\n",
    "    \n",
    "    for x,y in zip(ytest,ypredect):\n",
    "        \n",
    "        if x==y:\n",
    "            cntrow=cntrow+1\n",
    "  \n",
    "    accuracy=cntrow*100/ytestrow\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into pandas data frame\n",
    "df=read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split the X and Y data.\n",
    "x_train,x_test,y_train,y_test=preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate out continuous and categorical data of training data set.\n",
    "xtrain_cont_df,xtrain_cat_df,xtrain_cont_data,xtrain_cat_data=train_cat_cont_split(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate probability of unqiue values of Y data.\n",
    "class_dict,unqout=class_prob(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate std and mean of continuous columns of training data set\n",
    "train_std_mean=std_mean_cal(xtrain_cont_data,xtrain_cont_df,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate probability of every unique value of categorical columns of training data set given unique value of Y data(Red|Yes)\n",
    "xtrain_cat_prob=train_cat_prob(xtrain_cat_data,y_train,xtrain_cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the test data.\n",
    "ypred=predict_test(x_test,y_train,train_std_mean,xtrain_cat_prob,xtrain_cont_data,xtrain_cat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the accuracy score.\n",
    "accuracy_val=accuracyfunc(ypred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
